"""
Module x·ª≠ l√Ω d·ªØ li·ªáu cho d·ª± √°n ph√°t hi·ªán gian l·∫≠n th·∫ª t√≠n d·ª•ng.

Module n√†y cung c·∫•p c√°c h√†m ƒë·ªÉ:
- T·∫£i d·ªØ li·ªáu t·ª´ ngu·ªìn c√¥ng khai
- X·ª≠ l√Ω d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng b·∫±ng Oversampling v√† SMOTE
- Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra
"""

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import RandomOverSampler, SMOTE
import streamlit as st


# URL d·ªØ li·ªáu c√¥ng khai - Credit Card Fraud Detection t·ª´ Kaggle
DATA_URL = "https://raw.githubusercontent.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/master/creditcard.csv"


@st.cache_data
def load_data():
    """
    T·∫£i d·ªØ li·ªáu Credit Card Fraud Detection.
    
    Th·ª© t·ª± ∆∞u ti√™n:
    1. T·∫£i t·ª´ file local (data/creditcard.csv)
    2. N·∫øu kh√¥ng c√≥, t·∫£i t·ª´ URL c√¥ng khai
    
    Returns:
        pd.DataFrame: DataFrame ch·ª©a d·ªØ li·ªáu giao d·ªãch th·∫ª t√≠n d·ª•ng
    """
    # Th·ª≠ t·∫£i t·ª´ file local tr∆∞·ªõc
    try:
        base_dir = os.path.dirname(os.path.dirname(__file__))
        file_path = os.path.join(base_dir, "data", "creditcard.csv")
        
        if os.path.exists(file_path):
            placeholder = st.empty()
            placeholder.info("üìÇ ƒêang t·∫£i d·ªØ li·ªáu t·ª´ file local...")
            df = pd.read_csv(file_path)
            placeholder.success(f"‚úÖ ƒê√£ t·∫£i {len(df):,} giao d·ªãch t·ª´ file local")
            return df
        else:
            raise FileNotFoundError("File local kh√¥ng t·ªìn t·∫°i")
            
    except Exception as e:
        # Fallback: T·∫£i t·ª´ URL
        try:
            placeholder = st.empty()
            placeholder.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file local. ƒêang t·∫£i t·ª´ URL...")
            df = pd.read_csv(DATA_URL)
            placeholder.empty()  # X√≥a th√¥ng b√°o warning
            
            # T√πy ch·ªçn: L∆∞u file v·ªÅ local ƒë·ªÉ l·∫ßn sau d√πng
            try:
                os.makedirs(os.path.join(base_dir, "data"), exist_ok=True)
                df.to_csv(file_path, index=False)
                st.success(f"‚úÖ ƒê√£ t·∫£i {len(df):,} giao d·ªãch t·ª´ URL v√† l∆∞u v√†o file local")
            except:
                st.success(f"‚úÖ ƒê√£ t·∫£i {len(df):,} giao d·ªãch t·ª´ URL")
            
            return df
            
        except Exception as url_error:
            st.error(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu t·ª´ URL: {url_error}")
            st.info("üí° B·∫°n c√≥ th·ªÉ t·∫£i d·ªØ li·ªáu th·ªß c√¥ng t·ª´ Kaggle: https://www.kaggle.com/mlg-ulb/creditcardfraud")
            return None


def get_data_info(df):
    """
    L·∫•y th√¥ng tin t·ªïng quan v·ªÅ d·ªØ li·ªáu.
    
    Args:
        df (pd.DataFrame): DataFrame ch·ª©a d·ªØ li·ªáu
        
    Returns:
        dict: Dictionary ch·ª©a th√¥ng tin v·ªÅ d·ªØ li·ªáu
    """
    total_transactions = len(df)
    fraud_transactions = df['Class'].sum()
    fraud_percentage = (fraud_transactions / total_transactions) * 100
    
    return {
        'total_transactions': total_transactions,
        'fraud_transactions': fraud_transactions,
        'normal_transactions': total_transactions - fraud_transactions,
        'fraud_percentage': fraud_percentage
    }


def prepare_data(df, test_size=0.2, random_state=42):
    """
    Chu·∫©n b·ªã d·ªØ li·ªáu: t√°ch features v√† target, chu·∫©n h√≥a d·ªØ li·ªáu.
    
    - C·ªôt Time ƒë∆∞·ª£c lo·∫°i b·ªè (kh√¥ng s·ª≠ d·ª•ng)
    - C·ªôt Amount ƒë∆∞·ª£c chu·∫©n h√≥a
    - C√°c c·ªôt V1-V28 ƒë√£ ƒë∆∞·ª£c PCA n√™n KH√îNG c·∫ßn chu·∫©n h√≥a l·∫°i
    - Chu·∫©n h√≥a ƒë∆∞·ª£c th·ª±c hi·ªán TR∆Ø·ªöC khi chia train/test
    
    Args:
        df (pd.DataFrame): DataFrame ch·ª©a d·ªØ li·ªáu
        test_size (float): T·ª∑ l·ªá d·ªØ li·ªáu test
        random_state (int): Seed cho random state
        
    Returns:
        tuple: (X_train, X_test, y_train, y_test)
    """
    # T·∫°o b·∫£n sao ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn dataframe g·ªëc
    df_processed = df.copy()
    
    # B∆∞·ªõc 1: Chu·∫©n h√≥a c·ªôt Amount TR∆Ø·ªöC khi chia d·ªØ li·ªáu
    scaler = StandardScaler()
    df_processed['Amount'] = scaler.fit_transform(df_processed['Amount'].values.reshape(-1, 1))
    
    # B∆∞·ªõc 2: Lo·∫°i b·ªè c·ªôt Time (theo b√†i b√°o)
    df_processed = df_processed.drop('Time', axis=1)
    
    # B∆∞·ªõc 3: T√°ch features v√† target
    X = df_processed.drop('Class', axis=1)
    y = df_processed['Class']
    
    # B∆∞·ªõc 4: Chia d·ªØ li·ªáu train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    # Chuy·ªÉn v·ªÅ numpy array ƒë·ªÉ ph√π h·ª£p v·ªõi c√°c h√†m x·ª≠ l√Ω ti·∫øp theo
    X_train = X_train.values
    X_test = X_test.values
    
    return X_train, X_test, y_train, y_test


def apply_oversampling(X_train, y_train, random_state=42):
    """
    √Åp d·ª•ng ph∆∞∆°ng ph√°p Oversampling ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng.
    
    Ph∆∞∆°ng ph√°p n√†y l·∫∑p l·∫°i c√°c m·∫´u gian l·∫≠n (minority class) ƒë·ªÉ c√¢n b·∫±ng v·ªõi
    c√°c m·∫´u h·ª£p ph√°p (majority class).
    
    Args:
        X_train (np.array): D·ªØ li·ªáu training features
        y_train (pd.Series): D·ªØ li·ªáu training labels
        random_state (int): Seed cho random state
        
    Returns:
        tuple: (X_resampled, y_resampled)
    """
    ros = RandomOverSampler(random_state=random_state)
    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)
    
    return X_resampled, y_resampled


def apply_smote(X_train, y_train, random_state=42):
    """
    √Åp d·ª•ng ph∆∞∆°ng ph√°p SMOTE (Synthetic Minority Oversampling Technique).
    
    SMOTE t·∫°o ra c√°c m·∫´u gian l·∫≠n t·ªïng h·ª£p b·∫±ng c√°ch n·ªôi suy gi·ªØa c√°c m·∫´u
    gian l·∫≠n hi·ªán c√≥, thay v√¨ ch·ªâ ƒë∆°n gi·∫£n l·∫∑p l·∫°i ch√∫ng.
    
    Args:
        X_train (np.array): D·ªØ li·ªáu training features
        y_train (pd.Series): D·ªØ li·ªáu training labels
        random_state (int): Seed cho random state
        
    Returns:
        tuple: (X_resampled, y_resampled)
    """
    smote = SMOTE(random_state=random_state)
    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)
    
    return X_resampled, y_resampled


def get_resampling_info(y_original, y_resampled, method_name):
    """
    L·∫•y th√¥ng tin v·ªÅ k·∫øt qu·∫£ resampling.
    
    Args:
        y_original (pd.Series): Labels g·ªëc
        y_resampled (np.array): Labels sau khi resample
        method_name (str): T√™n ph∆∞∆°ng ph√°p resampling
        
    Returns:
        dict: Th√¥ng tin v·ªÅ resampling
    """
    original_fraud = y_original.sum()
    original_normal = len(y_original) - original_fraud
    original_total = len(y_original)
    
    resampled_fraud = y_resampled.sum()
    resampled_normal = len(y_resampled) - resampled_fraud
    resampled_total = len(y_resampled)
    
    return {
        'method': method_name,
        'original_total': original_total,
        'original_fraud': original_fraud,
        'original_normal': original_normal,
        'original_fraud_percentage': (original_fraud / original_total) * 100,
        'resampled_total': resampled_total,
        'resampled_fraud': resampled_fraud,
        'resampled_normal': resampled_normal,
        'resampled_fraud_percentage': (resampled_fraud / resampled_total) * 100
    }


def process_data_by_method(method, X_train, y_train):
    """
    X·ª≠ l√Ω d·ªØ li·ªáu theo ph∆∞∆°ng ph√°p ƒë∆∞·ª£c ch·ªçn.
    
    Args:
        method (str): Ph∆∞∆°ng ph√°p x·ª≠ l√Ω ('original', 'oversampling', 'smote')
        X_train, X_test: Training v√† test features
        y_train, y_test: Training v√† test labels
        
    Returns:
        tuple: (X_train_processed, y_train_processed, method_info)
    """
    if method == 'D·ªØ li·ªáu g·ªëc (M·∫•t c√¢n b·∫±ng)':
        method_info = get_resampling_info(y_train, y_train, 'D·ªØ li·ªáu g·ªëc')
        return X_train, y_train, method_info
        
    elif method == 'X·ª≠ l√Ω b·∫±ng Oversampling':
        X_resampled, y_resampled = apply_oversampling(X_train, y_train)
        method_info = get_resampling_info(y_train, y_resampled, 'Oversampling')
        return X_resampled, y_resampled, method_info
        
    elif method == 'X·ª≠ l√Ω b·∫±ng SMOTE':
        X_resampled, y_resampled = apply_smote(X_train, y_train)
        method_info = get_resampling_info(y_train, y_resampled, 'SMOTE')
        return X_resampled, y_resampled, method_info
